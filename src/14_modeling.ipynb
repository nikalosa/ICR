{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb9753ec668141f1f80f4e3510607ec34b3d510c",
    "id": "-HGq_7W8xZYa",
    "colab_type": "text"
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "7b592fbf048556ad450e850dc0a52b40300fa243",
    "id": "Yc51GNApxZYc",
    "colab_type": "code",
    "outputId": "4b023206-d9ed-4820-eafd-8db4b5fe937d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ჟ...\n",
      "Reading ტ...\n",
      "Reading რ...\n",
      "Reading ე...\n",
      "Reading ქ...\n",
      "Reading კ...\n",
      "Reading ჰ...\n",
      "Reading ყ...\n",
      "Reading ფ...\n",
      "Reading ი...\n",
      "Done Reading!\n",
      "Total Train Data : 10658\n",
      "Total Test  Data : 1191\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "input_path = './result/'\n",
    "\n",
    "letters = ['ე', 'ი', 'კ', 'ჟ', 'რ', 'ტ', 'ფ', 'ქ', 'ყ', 'ჰ']\n",
    "ratio = 0.90\n",
    " \n",
    "def getLetVec(letter):\n",
    "    vec = np.zeros((10,), dtype=int)\n",
    "    vec[letters.index(letter)] = 1\n",
    "    return [vec]\n",
    " \n",
    "def fill_data_for_folder(folder, train_data, test_data):\n",
    "    files = os.listdir('{}/{}'.format(input_path,folder))\n",
    "    result = getLetVec(folder)\n",
    "    cur_data = []\n",
    "    \n",
    "    for file in files:\n",
    "        image = Image.open(\"{}/{}/{}\".format(input_path,folder, file))\n",
    "        image = image.resize((40,40), resample = Image.BILINEAR)\n",
    "        image_array = np.array(image)/255\n",
    "        #print(image_array.shape)\n",
    "        if image_array.shape == (40,40):\n",
    "            #image_array = np.array(image)*(255.0/(np.array(image).max()))\n",
    "            cur_data += [(image_array, result)]\n",
    "\n",
    "    np.random.shuffle(cur_data)\n",
    "    \n",
    "    train_size = int(len(cur_data) * ratio)\n",
    "    \n",
    "    train_data += cur_data[:train_size]\n",
    "    test_data += cur_data[train_size:]\n",
    "\n",
    "def fill_data(train_data, test_data):\n",
    "    folders = os.listdir(input_path)\n",
    "    for folder in folders:\n",
    "        print('Reading {}...'.format(folder))\n",
    "        fill_data_for_folder(folder, train_data, test_data)\n",
    "    print(\"Done Reading!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    fill_data(train_data, test_data)\n",
    "    train_data = np.array(train_data)\n",
    "    test_data = np.array(test_data)\n",
    "\n",
    "    np.random.shuffle(train_data)\n",
    "\n",
    "    X_train = np.array(list(map(lambda x: x[0], train_data)))\n",
    "    Y_train = np.array(list(map(lambda x: x[1], train_data)))\n",
    "    \n",
    "    X_test = np.array(list(map(lambda x: x[0], test_data)))\n",
    "    Y_test = np.array(list(map(lambda x: x[1], test_data)))\n",
    "\n",
    "    print(\"Total Train Data : {}\".format(len(X_train)))\n",
    "    print(\"Total Test  Data : {}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e4c5da9e454a8add93ec8ca9edbb9dc459c3c46",
    "id": "W-g-nQkvxZYi",
    "colab_type": "text"
   },
   "source": [
    "# Filter Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "98393f8c34252c0be524eafd9b50cbe9ef9e7dc7",
    "id": "wJZywFQ8xZYi",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Filter:\n",
    "    \n",
    "    ### constructor takes array which will be filter\n",
    "    def __init__(self, filterM):\n",
    "        self.filter = np.array(filterM)\n",
    "        self.n = self.filter.shape[0]\n",
    "        self.m = self.filter.shape[1]\n",
    "        \n",
    "    ### returns filter\n",
    "    def get_filter(self):\n",
    "        return self.filter\n",
    "    \n",
    "    ### change filter by delta matrix\n",
    "    def add_delta(self, delta):\n",
    "        self.filter += delta\n",
    "\n",
    "    ### set the value of i,j element of the filter \n",
    "    def set(self, i, j, val):\n",
    "        self.filter[i][j] = val\n",
    "\n",
    "    ### returns the value of i,j element\n",
    "    def get(self, i, j):\n",
    "        return self.filter[i][j]\n",
    "\n",
    "    ### takes matrix and returns filtered matrix\n",
    "    def go_filter(self, data):\n",
    "        resultdata = np.zeros((data.shape[0] - self.n + 1, data.shape[1] - self.m + 1))\n",
    "        for i in range(data.shape[0] - self.n + 1):\n",
    "            for j in range(data.shape[1] - self.m + 1):\n",
    "                resultdata[i][j] = np.sum(self.filter * data[i:i+self.n,j:j+self.m])\n",
    "        return resultdata\n",
    "    \n",
    "    ### takes matrix and poolfilter dimension, returns max-pooled matrix\n",
    "    def go_maxpool(self, data, n, m):\n",
    "        resultdata = np.zeros((int(data.shape[0] / n) , int(data.shape[1] / m)))\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0, data.shape[1], m):\n",
    "                resultdata[int(i/n)][int(j/m)] = np.max(data[i:i+n, j:j+m])\n",
    "        return resultdata\n",
    "    \n",
    "    def go_maxpool(self,data,n,m):\n",
    "        resultdata = np.zeros(data.shape[0] / n , data.shape[1] / m)\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0,data.shape[1], m):\n",
    "                resultdata[i/n][j/m] = data[i:i+n, j:j+m].mean()\n",
    "        resultdata\n",
    "        \n",
    "        \n",
    "    def avarage_pooling_backforward(self,data, loss_data, n, m):\n",
    "        updated_data = np.zeros(data.shape)\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0,data.shape[1], m):\n",
    "                data[i: i + n, j: j + m] = (m*n)*resultdata[i/n][j/m]\n",
    "\n",
    "    # pshiu, this method is pretty complex but in few words it updates convolutional filter\n",
    "    # looking at loss matrix and pre-matrixes.\n",
    "    def update_filter_one_matrix(self, data, loss_data):\n",
    "        learning_rate = 0.0003\n",
    "        updated_filter = np.zeros(self.filter.shape)\n",
    "        updated_data = np.zeros(data.shape)\n",
    "        for i in range(data.shape[0] + 1 - self.n):\n",
    "            for j in range(data.shape[1] + 1 - self.m):\n",
    "                # in summary resultdata[i][j] = self.filter * data[i:i+self.n, j : j+self.m]\n",
    "                my_filter_part_data = data[i:i+self.n, j : j+self.m]\n",
    "                my_data_part_data = updated_data[i:i+self.n, j : j+self.m]\n",
    "                for x in range(my_filter_part_data.shape[0]):\n",
    "                    for y in range(my_filter_part_data.shape[1]):\n",
    "                        updated_filter[x][y] += loss_data[i][j]*my_filter_part_data[x][y]\n",
    "                        # x derivative\n",
    "                        my_data_part_data[x][y] +=loss_data[i][j]*self.filter[x][y]\n",
    "                updated_data[i:i+self.n, j : j+self.m] = my_data_part_data\n",
    "        self.filter =self.filter -  learning_rate*updated_filter\n",
    "        return updated_filter, updated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6bcec29ff6752962ef1ad152e80ef2b8b077295",
    "id": "Y9mShm-JxZYk",
    "colab_type": "text"
   },
   "source": [
    "# Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "1f3818dda35a568df97b3aab99bef302bf843d7b",
    "id": "P34scU9wxZYm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "class Layer:\n",
    "    ### constructor takes the list of filters \n",
    "    def __init__(self, num_filters):\n",
    "        self.filters = []\n",
    "        self.num_filters = num_filters\n",
    "        self.matrixes = []\n",
    "        self.preMatrixes = []\n",
    "        self.n = 2\n",
    "        self.m = 3\n",
    "    \n",
    "    ### returns the i-th filter\n",
    "    def get_filter(self, i):\n",
    "        return self.filters[i]\n",
    "    \n",
    "    ### return the list of filters\n",
    "    def get_filters(self):\n",
    "        return self.filters\n",
    "    \n",
    "    ### generates list of matrixes, from previous layer's matrixes and it's filters\n",
    "    def gen_matrixes(self, preMatrixes):\n",
    "        if len(self.filters) == 0:\n",
    "            for x in range(len(preMatrixes)):\n",
    "                each_filters = [Filter(np.random.randn(2,3)) for _ in range(self.num_filters)]\n",
    "                self.filters.append(each_filters)\n",
    "                \n",
    "        self.preMatrixes = preMatrixes\n",
    "        my_matrixes = [np.zeros((self.preMatrixes[0].shape[0] - self.n + 1, self.preMatrixes[0].shape[1] - self.m + 1)) for _ in range(self.num_filters)]\n",
    "\n",
    "        for x in range(len(preMatrixes)):\n",
    "            mat = preMatrixes[x]\n",
    "            temp = 0\n",
    "            for filt in self.filters[x]:\n",
    "                my_matrixes[temp] += filt.go_filter(mat)\n",
    "                temp+=1\n",
    "        self.matrixes = my_matrixes\n",
    "            \n",
    "        \n",
    "    ### returns i-th matrix of our matrixs' list\n",
    "    def get_matrix(self, i):\n",
    "        return self.matrix[i]\n",
    "    \n",
    "    ### returns list of matrixes\n",
    "    def get_matrixes(self):\n",
    "        return self.matrixes\n",
    "    \n",
    "    def layer_back_forward(self, loss_data_list):\n",
    "\n",
    "\n",
    "        pre_matrix_list = self.preMatrixes\n",
    "        updated_pre_matrix = [np.zeros(matr.shape) for matr in pre_matrix_list]\n",
    "        \n",
    "        updated_filters = []\n",
    "\n",
    "        for x in range(len(self.filters)):\n",
    "            each_filters = [np.zeros(matr.get_filter().shape) for matr in self.filters[x]]\n",
    "            updated_filters.append(each_filters)\n",
    "#         print(self.filters)\n",
    "        for x in range(len(self.filters)):\n",
    "            filt = self.filters[x]\n",
    "            for index in range(len(filt)):\n",
    "                cur_filt = filt[index]\n",
    "                cur_loss_data = loss_data_list[index]\n",
    "                for y in range(len(pre_matrix_list)):\n",
    "                    mat = pre_matrix_list[y]\n",
    "                    updated_filter, updated_data = cur_filt.update_filter_one_matrix(mat, cur_loss_data)\n",
    "                    updated_filters[x][index]+=updated_filter\n",
    "                    updated_pre_matrix[y]+=updated_data\n",
    "        return updated_pre_matrix\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c534a5364e008346d87ccca196ba5e774704892",
    "id": "fhIA5uGpxZYp",
    "colab_type": "text"
   },
   "source": [
    "# CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "d27d2705c6be60aa2c4b84e3b05cfbe7d1784cc6",
    "id": "5B95YKCmxZYp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    ### constructor takes the starting matrix and filters list for each layer\n",
    "    ### layerFilters is 4D list\n",
    "    ### a = CNN(ar, )\n",
    "    ## update.\n",
    "    ## layerFilters listshi mewera listi filtrebisa layerebis mixedvit\n",
    "    ## exla shignit ubralod ricxvs chavwer tu ramdeni filtri unda mas.\n",
    "    def __init__(self, stMatrix, layerFilters):\n",
    "        self.stMatrix = stMatrix\n",
    "        self.layers = []\n",
    "        for layerFilter in layerFilters:\n",
    "#             print(layerFilter)\n",
    "            self.layers.append(Layer(layerFilter))\n",
    "    \n",
    "    ### returns all layer objects \n",
    "    def get_layers(self):\n",
    "        return self.layers\n",
    "    def set_x(self,X):\n",
    "        self.stMatrix = X\n",
    "    \n",
    "    ### returns i-th layer\n",
    "    def get_layer(self, i):\n",
    "        return self.layers[i]\n",
    "        \n",
    "    ### returns flattened np-array for fully connection NL\n",
    "    def forward_prop(self):\n",
    "        matrixList = [self.stMatrix]\n",
    "        for layer in self.layers:\n",
    "            layer.gen_matrixes(matrixList)\n",
    "            matrixList = layer.get_matrixes()\n",
    "        return self.flatten(matrixList)\n",
    "            \n",
    "    ### static method, flattens 3D array\n",
    "    def flatten(self, matrixList):\n",
    "\n",
    "        lst = []\n",
    "        for matrix in matrixList:\n",
    "            lst+=(matrix.flatten().tolist())\n",
    "        return lst\n",
    "    \n",
    "    def unflatten(self, flatten_matrix):\n",
    "        my_matrix = self.layers[len(self.layers)-1].get_matrixes()\n",
    "        my_loss_matrix = [np.zeros(tmp.shape) for tmp in my_matrix]\n",
    "        temp = 0\n",
    "        for index in range(len(my_loss_matrix)):\n",
    "            mat = my_loss_matrix[index]\n",
    "            for x in range(mat.shape[0]):\n",
    "                for y in range(mat.shape[1]):\n",
    "                    my_loss_matrix[index][x][y] = flatten_matrix[0][temp]\n",
    "                    temp += 1\n",
    "        return my_loss_matrix\n",
    "        \n",
    "    def backward(self, delta_x):\n",
    "        new_delta_x = delta_x\n",
    "        for layer in reversed(self.layers):\n",
    "            #WINEBIS listi da loss_datas listi\n",
    "            new_delta_x = layer.layer_back_forward(new_delta_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8286da8cc49f6c41c7d9e253333081a579dbfaa8",
    "id": "aVpShj4rxZYs",
    "colab_type": "text"
   },
   "source": [
    "# Dance NL Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "4bd505246e1578159eb5fb02027752aca7a0fc98",
    "id": "LdAGJfS_xZYt",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    \n",
    "    ### constructor takes parameter's array(flattened array) and answer array(1x10)\n",
    "    def __init__(self, X, Y):\n",
    "        self.i=0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.cachedLoss = []\n",
    "    \n",
    "    # just return e^(-z)\n",
    "    def my_exp(self,z):\n",
    "        return np.exp(-z)\n",
    "    \n",
    "    def set_y(self, Y):\n",
    "        self.Y=Y\n",
    "    \n",
    "    def set_matrix(self,mat):\n",
    "        if self.X is None:\n",
    "            self.W0 = np.random.randn(mat.size, 64)/100\n",
    "            self.W1 = np.random.randn(64, 10)/100\n",
    "        self.X = mat\n",
    "        \n",
    "        \n",
    "        # our zigmoid function\n",
    "    def zigmoid_function(self,z):\n",
    "        return 1/(1 + self.my_exp(z))\n",
    "    \n",
    "    def costfn_class(self, X, y):\n",
    "#         X = self.zigmoid_function(X)\n",
    "        error= -1*y*np.log(X) + (y-1)*np.log(1-X)\n",
    "#         my_sum = np.sum(abs(error))\n",
    "        return error\n",
    "    \n",
    "    def cross_entropy(self, predictions, targets, epsilon=1e-10):\n",
    "        predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "        ce = targets*np.log(predictions+1e-9) + (targets - 1)*np.log(1-predictions + 1e-9)\n",
    "        return ce\n",
    "    \n",
    "    \n",
    "        # ferivative of our zigmoid function\n",
    "    def derivative_zigmoid(self,z):\n",
    "        return self.my_exp(z) / np.power((1 + self.my_exp(z)), 2)\n",
    "    \n",
    "    # our fucntion doing feed forward alghoritm.\n",
    "    def feed_forward(self,X, W0, W1):\n",
    "        h0 = np.dot(X, W0)  # our first matrix after using first hidden layer W0\n",
    "    #     h0 = zigmoid_function(h0)  # our first matrix using zigmoid.\n",
    "        \n",
    "        h3 = np.dot(h0, W1) # our result after using second hidden layer W1\n",
    "        h1 = self.zigmoid_function(h3) # our result matrix after using zigmoid.\n",
    "        return h0, h1 # return result.\n",
    "    \n",
    "    # compute our error which is h1-y but we also take into consideration the zigmoid function.\n",
    "    def my_error(self,h1):\n",
    "#         error = h1 - self.Y\n",
    "#         return error\n",
    "        return self.cross_entropy(h1,self.Y)\n",
    "\n",
    "\n",
    "    def backward(self,X, W0, W1, h1, h0, alfa_rate):\n",
    "        # firstly lets compute error h1-y\n",
    "        error = self.my_error(h1)\n",
    "#         if self.cachedLoss != []:\n",
    "#             error = error*0.1 + 0.9*self.cachedLoss\n",
    "#         self.cachedLoss = error    \n",
    "        \n",
    "        bla_W1 = W1\n",
    "        # first lets update W1 which is far easier W1 = (h0)T *(h1 - Y)\n",
    "        transpose_h0 = np.transpose(h0)\n",
    "        error = error * self.derivative_zigmoid(h1)\n",
    "\n",
    "        # now lets update W0 too which is bit complex.\n",
    "        # W0 = XT.(ERROR).W1T\n",
    "        transpose_X = np.transpose(X)\n",
    "        transpose_W1 = np.transpose(bla_W1)\n",
    "\n",
    "\n",
    "        first_step = np.dot(error, transpose_W1)\n",
    "        second_step = np.dot(transpose_X, first_step)\n",
    "        delta_x = np.dot(error, np.transpose(np.dot(self.W0, self.W1)))\n",
    "        W0 -= second_step*alfa_rate\n",
    "        W1 -= np.dot (transpose_h0, error)*alfa_rate\n",
    "        return delta_x\n",
    "    \n",
    "\n",
    "    def predict(self, back):\n",
    "        h0, h1 = self.feed_forward(self.X, self.W0, self.W1)\n",
    "        delta_x = None\n",
    "        if back:\n",
    "            delta_x = self.backward(self.X, self.W0, self.W1, h1, h0, 0.0005)\n",
    "        return delta_x, h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4174df2f6d35a9027a515d3993efdd82a7f7fe57",
    "id": "8vH-8yxCxZYw",
    "colab_type": "text"
   },
   "source": [
    "# **Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "81f55cc00f89609a8eabe4f28e5fda6bd6c7f84c",
    "id": "L9o0x6YVxZYw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# first_layer_filters = []\n",
    "# first_layer_filters.append(1)\n",
    "\n",
    "# # here we will initialize second layer filters\n",
    "# # second_layer_filter = Filter(np.random.randn(3,3))\n",
    "# second_layer_filters = []\n",
    "# second_layer_filters.append(1)\n",
    "\n",
    "# here we will initialize second layer filters\n",
    "filter_array = []\n",
    "filter_array.append(3)\n",
    "filter_array.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "2591d2b3cb56e7c578e088e6e736fdb82b440792",
    "id": "blHvJtyZxZY0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "##### lets initialize CNN class\n",
    "cnn = CNN(None,filter_array)\n",
    "dense_class = Dense(None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "055b2f0c0b5b560a9413d3161aa872a2e108a63b",
    "id": "dY7aTy16xZY4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def predict(cnn,dense_class, back):\n",
    "    flatten_array = np.array(cnn.forward_prop())\n",
    "    flatten_array = np.reshape(np.array(flatten_array), (flatten_array.shape[0],1))\n",
    "    \n",
    "    #now lets start with dense class to work with neural network.\n",
    "    flatten_array = np.transpose(flatten_array)\n",
    "    \n",
    "    # dense_class = Dense(np.transpose(flatten_array),Y)\n",
    "    dense_class.set_matrix(flatten_array)\n",
    "    delta_x, h1 = dense_class.predict(back)\n",
    "    \n",
    "    if back:\n",
    "        #listi maq matricebis\n",
    "        delta_x = cnn.unflatten(delta_x)\n",
    "        cnn.backward(delta_x)\n",
    "        \n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "72e34f706ac1f3701f32f12eca1fc009a690d87d",
    "id": "ZtERwwlkxZY6",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def go_forest(X, Y, debug=False, back = True):\n",
    "    cnn.set_x(X)\n",
    "    dense_class.set_y(Y)\n",
    "    for _ in range(1):\n",
    "        h1 = predict(cnn, dense_class, back)\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "04527ec331f379e077cc610fb9eaaf5d3ce31454",
    "id": "VAiBNGO0xZY9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def check_for_debug(index, total, percentage,):\n",
    "    if percentage < 1:\n",
    "        to_divide = total*percentage/100\n",
    "    else:\n",
    "        to_divide = int(total*percentage/100)\n",
    "    if to_divide == 0 or index%to_divide == 0:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def print_train_debug(index, total, percentage):\n",
    "    prc = (100*index/total)\n",
    "    str = 'Done {}%!'.format(prc)\n",
    "    print()\n",
    "    print(str)\n",
    "    \n",
    "    bar = '=' * int(prc)\n",
    "    bar += '-'*int(100-prc)\n",
    "    bar_str = '[{}]'.format(bar)\n",
    "    print(bar_str)\n",
    "    \n",
    "def print_test_debug(index, total, percentage, ans):\n",
    "    prc = int(100*index/total)\n",
    "    true_prc = 0\n",
    "    if index:\n",
    "        true_prc = int(100*ans/(index+1))\n",
    "    str = 'Done {}%.. Result {}/{} ({}%)'.format(prc,ans,index,true_prc)\n",
    "    print(str)\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "bc208ae86c38643b62f51621558ac024e5646863",
    "id": "uFIjFZyCxZY-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "percentage = 1\n",
    "# total = 100\n",
    "total = int(len(X_train))\n",
    "print(total)\n",
    "ans = 0\n",
    "ansbla = [0,0,0,0,0,0,0,0,0,0]\n",
    "count = [0,0,0,0,0,0,0,0,0,0]\n",
    "for index in range(0, total):\n",
    "    debug = True\n",
    "    if check_for_debug(index, total, percentage):\n",
    "        print_test_debug(index, total, percentage, ans)\n",
    "#         for i in range(10):\n",
    "#             x = 0\n",
    "#             if count[i] > 0:\n",
    "#                 x = float(ansbla[i]/count[i])*100\n",
    "#             print(letters[i],'----> ',x, '%')\n",
    "        debug = True\n",
    "    h = go_forest(X_train[index],Y_train[index], debug)\n",
    "    ind1 = find_max_ind(h)\n",
    "    ind2 = find_max_ind(Y_train[index]) \n",
    "    #count[ind2] += 1\n",
    "    if ind1 == ind2:\n",
    "        ans += 1\n",
    "     #   ansbla[ind2] += 1\n",
    "# print_train_debug(total, total, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "e8bf58713e2d37f342b1325a35f53cbc3b6e6406",
    "id": "K7iFv77SxZZB",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def find_max_ind(arr):\n",
    "    index = 0\n",
    "    max_num = arr[0][0]\n",
    "    for i in range(len(arr[0])):\n",
    "        if arr[0][i] > max_num:\n",
    "            max_num = arr[0][i]\n",
    "            index = i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "scrolled": false,
    "_uuid": "eb474931b9486db91e01db1da794ba5dd7ceefac",
    "id": "YtUw_ww7xZZE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "total = len(X_test)\n",
    "percentage = 5\n",
    "ans = 0\n",
    "ansbla = [0,0,0,0,0,0,0,0,0,0]\n",
    "count = [0,0,0,0,0,0,0,0,0,0]\n",
    "for ind in range(total):\n",
    "    if check_for_debug(ind, total, percentage):\n",
    "        print_test_debug(ind, total, percentage, ans)\n",
    "        for i in range(10):\n",
    "            x = 0\n",
    "            if count[i] > 0:\n",
    "                x = float(ansbla[i]/count[i])*100\n",
    "            print(letters[i],'----> ',x, '%')\n",
    "    h = go_forest(X_test[ind],Y_test[ind], True, False)\n",
    "    \n",
    "    ind1 = find_max_ind(h)\n",
    "    ind2 = find_max_ind(Y_test[ind])\n",
    "    count[ind2] += 1\n",
    "    if ind1 == ind2:\n",
    "        ans += 1\n",
    "        ansbla[ind2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "f0edde767b0f38404b55882364e9a3f059d56bc6",
    "id": "k_1NXCBgxZZG",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "ca59dd84f28ea71517ad41ef95fd075d1638a6e1",
    "id": "vppw7Yd7xZZI",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "class Final:\n",
    "    def __init__(self, cnnOBJ, denseOBJ):\n",
    "        self.cnn = cnnOBJ\n",
    "        self.dense = denseOBJ\n",
    "        self.letters = ['ე', 'ი', 'კ', 'ჟ', 'რ', 'ტ', 'ფ', 'ქ', 'ყ', 'ჰ']\n",
    "        \n",
    "    def find_max_ind(arr):\n",
    "      index = 0\n",
    "      max_num = arr[0][0]\n",
    "      for i in range(len(arr[0])):\n",
    "          if arr[0][i] > max_num:\n",
    "              max_num = arr[0][i]\n",
    "              index = i\n",
    "      return index\n",
    "        \n",
    "    def go(self, img):\n",
    "        h = go_forest(img, [[1,0,0,0,0,0,0,0,0,0]], True, False)\n",
    "        ind = find_max_ind(h)\n",
    "        return self.letters[ind]\n",
    "    \n",
    "    def go_forest(X, Y, debug=False, back = True):\n",
    "        self.cnn.set_x(X)\n",
    "        self.dense.set_y(Y)\n",
    "        for _ in range(1):\n",
    "            h1 = predict(self.cnn, self.dense, back)\n",
    "        return h1\n",
    "    \n",
    "    def predict(cnn, dense_class, back):\n",
    "        flatten_array = np.array(cnn.forward_prop())\n",
    "        flatten_array = np.reshape(np.array(flatten_array), (flatten_array.shape[0],1))\n",
    "\n",
    "        #now lets start with dense class to work with neural network.\n",
    "        flatten_array = np.transpose(flatten_array)\n",
    "\n",
    "        # dense_class = Dense(np.transpose(flatten_array),Y)\n",
    "        dense_class.set_matrix(flatten_array)\n",
    "        delta_x, h1 = dense_class.predict(back)\n",
    "\n",
    "        if back:\n",
    "            #listi maq matricebis\n",
    "            delta_x = cnn.unflatten(delta_x)\n",
    "            cnn.backward(delta_x)\n",
    "\n",
    "        return h1\n",
    "\n",
    "FinalOBJ = Final(cnn,dense_class)    \n",
    "    \n",
    "import pickle\n",
    "\n",
    "filehandler = open(\"savedModel1.pkl\", 'wb') \n",
    "pickle.dump(FinalOBJ, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "J4iMdOYHy40k",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!unzip './result.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "trusted": true,
    "_uuid": "dc75dc065476e794d3a8e94457dbcdcaa466aed8",
    "id": "j_aD54rPxZZK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "14_modeling.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
