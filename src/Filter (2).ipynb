{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "beqa=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Filter:\n",
    "    \n",
    "    ### constructor takes array which will be filter\n",
    "    def __init__(self, filterM):\n",
    "        self.filter = np.array(filterM)\n",
    "        self.n = self.filter.shape[0]\n",
    "        self.m = self.filter.shape[1]\n",
    "        \n",
    "    ### returns filter\n",
    "    def get_filter(self):\n",
    "        return self.filter\n",
    "    \n",
    "    ### change filter by delta matrix\n",
    "    def add_delta(self, delta):\n",
    "        self.filter += delta\n",
    "\n",
    "    ### set the value of i,j element of the filter \n",
    "    def set(self, i, j, val):\n",
    "        self.filter[i][j] = val\n",
    "\n",
    "    ### returns the value of i,j element\n",
    "    def get(self, i, j):\n",
    "        return self.filter[i][j]\n",
    "\n",
    "    ### takes matrix and returns filtered matrix\n",
    "    def go_filter(self, data):\n",
    "        resultdata = np.zeros((data.shape[0] - self.n + 1, data.shape[1] - self.m + 1))\n",
    "        for i in range(data.shape[0] - self.n + 1):\n",
    "            for j in range(data.shape[1] - self.m + 1):\n",
    "                resultdata[i][j] = np.sum(self.filter * data[i:i+self.n,j:j+self.m])\n",
    "        return resultdata\n",
    "    \n",
    "    ### takes matrix and poolfilter dimension, returns max-pooled matrix\n",
    "    def go_maxpool(self, data, n, m):\n",
    "        resultdata = np.zeros((int(data.shape[0] / n) , int(data.shape[1] / m)))\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0, data.shape[1], m):\n",
    "                #print(i,j)\n",
    "                resultdata[int(i/n)][int(j/m)] = np.max(data[i:i+n, j:j+m])\n",
    "        return resultdata\n",
    "    \n",
    "    def update_filter_one_matrix(self, data, loss_data):\n",
    "        updated_filter = np.zeros(self.filter.shape)\n",
    "        updated_data = np.zeros(data.shape)\n",
    "        for i in range(data.shape[0] + 1 - self.n):\n",
    "            for j in range(data.shape[1] + 1 - self.m):\n",
    "                # in summary resultdata[i][j] = self.filter * data[i:i+self.n, j : j+self.m]\n",
    "                my_filter_part_data = data[i:i+self.n, j : j+self.m]\n",
    "                my_data_part_data = updated_data[i:i+self.n, j : j+self.m]\n",
    "                for x in range(my_filter_part_data.shape[0]):\n",
    "                    for y in range(my_filter_part_data.shape[1]):\n",
    "                        updated_filter[x][y] += loss_data[i][j]*my_filter_part_data[x][y]\n",
    "                        # x derivative\n",
    "                        my_data_part_data[x][y] +=loss_data[i][j]*self.filter[x][y]\n",
    "                updated_data[i:i+self.n, j : j+self.m] = my_data_part_data\n",
    "        self.filter =self.filter -  learning_rate*updated_filter\n",
    "#         print(updated_filter)\n",
    "        return updated_filter, updated_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# my_filter = Filter(np.array([1,2],[3,4]))\n",
    "filt = np.array([[1,2],[3,4]])\n",
    "data = np.array([[1,2],[3,4]])\n",
    "loss = np.array([[1,1],[1,1]])\n",
    "my_filter = Filter(filt)\n",
    "a,b = my_filter.update_filter_one_matrix(data,loss)\n",
    "print(type(filt))\n",
    "\n",
    "# filt-= a*learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt= filt - a*learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Layer:\n",
    "    ### constructor takes the list of filters \n",
    "    def __init__(self, num_filters):\n",
    "#         self.updated_filters = [np.zeros(matr.shape) for matr in self.filters]\n",
    "#         self.filters = [np.random.randn(2,2) for x in range(num_filters)]\n",
    "        self.filters = []\n",
    "        self.num_filters = num_filters\n",
    "        self.matrixes = []\n",
    "        self.preMatrixes = []\n",
    "        self.n = 2\n",
    "        self.m = 2\n",
    "    \n",
    "    ### returns the i-th filter\n",
    "    def get_filter(self, i):\n",
    "        return self.filters[i]\n",
    "    \n",
    "    ### return the list of filters\n",
    "    def get_filters(self):\n",
    "        return self.filters\n",
    "    \n",
    "    ### generates list of matrixes, from previous layer's matrixes and it's filters\n",
    "    def gen_matrixes(self, preMatrixes):\n",
    "        if len(self.filters) == 0:\n",
    "            for x in range(len(preMatrixes)):\n",
    "                each_filters = [Filter(np.random.randn(2,2)) for _ in range(self.num_filters)]\n",
    "                self.filters.append(each_filters)\n",
    "                \n",
    "        self.preMatrixes = preMatrixes\n",
    "#         print(len(self.preMatrixes))\n",
    "        my_matrixes = [np.zeros((self.preMatrixes[0].shape[0] - self.n + 1, self.preMatrixes[0].shape[1] - self.m + 1)) for _ in range(self.num_filters)]\n",
    "#         print(\"aeeeee\")\n",
    "#         print(my_matrixes)\n",
    "        for x in range(len(preMatrixes)):\n",
    "            mat = preMatrixes[x]\n",
    "            temp = 0\n",
    "            for filt in self.filters[x]:\n",
    "                my_matrixes[temp] += filt.go_filter(mat)\n",
    "                temp+=1\n",
    "        self.matrixes = my_matrixes\n",
    "            \n",
    "        \n",
    "    ### returns i-th matrix of our matrixs' list\n",
    "    def get_matrix(self, i):\n",
    "        return self.matrix[i]\n",
    "    \n",
    "    ### returns list of matrixes\n",
    "    def get_matrixes(self):\n",
    "        return self.matrixes\n",
    "    \n",
    "    def layer_back_forward(self, loss_data_list):\n",
    "\n",
    "\n",
    "        pre_matrix_list = self.preMatrixes\n",
    "        updated_pre_matrix = [np.zeros(matr.shape) for matr in pre_matrix_list]\n",
    "        \n",
    "        updated_filters = []\n",
    "\n",
    "        for x in range(len(self.filters)):\n",
    "            each_filters = [np.zeros(matr.get_filter().shape) for matr in self.filters[x]]\n",
    "            updated_filters.append(each_filters)\n",
    "#         print(self.filters)\n",
    "        for x in range(len(self.filters)):\n",
    "            filt = self.filters[x]\n",
    "            for index in range(len(filt)):\n",
    "                cur_filt = filt[index]\n",
    "                cur_loss_data = loss_data_list[index]\n",
    "                for y in range(len(pre_matrix_list)):\n",
    "                    mat = pre_matrix_list[y]\n",
    "                    updated_filter, updated_data = cur_filt.update_filter_one_matrix(mat, cur_loss_data)\n",
    "                    updated_filters[x][index]+=updated_filter\n",
    "                    updated_pre_matrix[y]+=updated_data\n",
    "#         self.filters -= learning_rate*updated_filters\n",
    "#         for x in range(len(self.filters)):\n",
    "#             filt_list = self.filters[x]\n",
    "#             for y in range(len(filt_list)):\n",
    "#                 self.filters[x][y]-=learning_rate*updated_filters[x][y]\n",
    "                \n",
    "        \n",
    "        \n",
    "        return updated_pre_matrix\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    ### constructor takes the starting matrix and filters list for each layer\n",
    "    ### layerFilters is 4D list\n",
    "    ### a = CNN(ar, )\n",
    "    ## update.\n",
    "    ## layerFilters listshi mewera listi filtrebisa layerebis mixedvit\n",
    "    ## exla shignit ubralod ricxvs chavwer tu ramdeni filtri unda mas.\n",
    "    def __init__(self, stMatrix, layerFilters):\n",
    "        self.stMatrix = stMatrix\n",
    "        self.layers = []\n",
    "        for layerFilter in layerFilters:\n",
    "#             print(layerFilter)\n",
    "            self.layers.append(Layer(layerFilter))\n",
    "    \n",
    "    ### returns all layer objects \n",
    "    def get_layers(self):\n",
    "        return self.layers\n",
    "    def set_x(self,X):\n",
    "        self.stMatrix = X\n",
    "    \n",
    "    ### returns i-th layer\n",
    "    def get_layer(self, i):\n",
    "        return self.layers[i]\n",
    "        \n",
    "    ### returns flattened np-array for fully connection NL\n",
    "    def forward_prop(self):\n",
    "        matrixList = [self.stMatrix]\n",
    "        for layer in self.layers:\n",
    "            layer.gen_matrixes(matrixList)\n",
    "            matrixList = layer.get_matrixes()\n",
    "        return self.flatten(matrixList)\n",
    "            \n",
    "    ### static method, flattens 3D array\n",
    "    def flatten(self, matrixList):\n",
    "#         print(matrixList)\n",
    "#         print(\"chemi listukaa\")\n",
    "#         print(len(matrixList))\n",
    "        lst = []\n",
    "        for matrix in matrixList:\n",
    "            #print(matrix,matrix.flatten())\n",
    "            lst+=(matrix.flatten().tolist())\n",
    "        return lst\n",
    "    \n",
    "    def unflatten(self, flatten_matrix):\n",
    "        my_matrix = self.layers[len(self.layers)-1].get_matrixes()\n",
    "#         print(self.layers[0])\n",
    "        my_loss_matrix = [np.zeros(tmp.shape) for tmp in my_matrix]\n",
    "        temp = 0\n",
    "        for index in range(len(my_loss_matrix)):\n",
    "            mat = my_loss_matrix[index]\n",
    "            for x in range(mat.shape[0]):\n",
    "                for y in range(mat.shape[1]):\n",
    "#                     print(my_loss_matrix[index][x][y])\n",
    "                    my_loss_matrix[index][x][y] = flatten_matrix[0][temp]\n",
    "                    temp+=1\n",
    "        return my_loss_matrix\n",
    "        \n",
    "    def backward(self, delta_x):\n",
    "#         print(len(self.layers))\n",
    "#         pass\n",
    "#         print(delta_x)\n",
    "        new_delta_x = delta_x\n",
    "        for layer in reversed(self.layers):\n",
    "            #WINEBIS listi da loss_datas listi\n",
    "            new_delta_x =layer.layer_back_forward(new_delta_x)\n",
    "        \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = CNN(np.array[np.random.randn(4,4)],[[Filter([[1,1],[1,1]])]])\n",
    "# print(cnn.forward_prop())\n",
    "# #CNN.flatten([np.array([[1,2],[3,4]]),np.array([[1,2,3],[3,4,5]])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dance NL Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    \n",
    "    ### constructor takes parameter's array(flattened array) and answer array(1x10)\n",
    "    def __init__(self, X, Y):\n",
    "        self.i=0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "#         print(X.shape)\n",
    "#         print(Y.shape)\n",
    "#         print(self.theta0.shape)\n",
    "#         print(self.theta1.shape)\n",
    "       \n",
    "        # just return e^(-z)\n",
    "    def my_exp(self,z):\n",
    "        return np.exp(-z)\n",
    "    \n",
    "    def set_y(self, Y):\n",
    "        self.Y=Y\n",
    "    \n",
    "    def set_matrix(self,mat):\n",
    "        if self.X is None:\n",
    "            self.W0 = np.random.randn(mat.size, 64)\n",
    "            self.W1 = np.random.randn(64, 10)\n",
    "        self.X = mat\n",
    "        \n",
    "        \n",
    "        # our zigmoid function\n",
    "    def zigmoid_function(self,z):\n",
    "        return 1/(1 + self.my_exp(z))\n",
    "    \n",
    "    def costfn_class(self, X, y):\n",
    "#         X = self.zigmoid_function(X)\n",
    "        error= -1*y*np.log(X) + (y-1)*np.log(1-X)\n",
    "#         my_sum = np.sum(abs(error))\n",
    "        return error\n",
    "    \n",
    "    def cross_entropy(self, predictions, targets, epsilon=1e-10):\n",
    "#         predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "#         N = predictions.shape[0]\n",
    "#         ce_loss = targets * np.log(predictions + 1e-5)\n",
    "#         return ce_loss    \n",
    "        predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "        N = predictions.shape[0]\n",
    "        ce = -1*targets*np.log(predictions+1e-9) + (targets - 1)*np.log(1-predictions + 1e-9)\n",
    "        return ce\n",
    "    \n",
    "    \n",
    "        # ferivative of our zigmoid function\n",
    "    def derivative_zigmoid(self,z):\n",
    "        return self.my_exp(z) / np.power((1 + self.my_exp(z)), 2)\n",
    "    \n",
    "    # our fucntion doing feed forward alghoritm.\n",
    "    def feed_forward(self,X, W0, W1):\n",
    "        h0 = np.dot(X, W0)  # our first matrix after using first hidden layer W0\n",
    "    #     h0 = zigmoid_function(h0)  # our first matrix using zigmoid.\n",
    "        \n",
    "        h3 = np.dot(h0, W1) # our result after using second hidden layer W1\n",
    "        h1 = self.zigmoid_function(h3) # our result matrix after using zigmoid.\n",
    "        return h0, h1 # return result.\n",
    "    \n",
    "    # compute our error which is h1-y but we also take into consideration the zigmoid function.\n",
    "    def my_error(self,h1):\n",
    "        error = h1 - self.Y\n",
    "        return error\n",
    "\n",
    "    def costfn(self,h1):\n",
    "        error = self.my_error(h1)\n",
    "        my_sum = np.sum(abs(error))\n",
    "        return my_sum/len(error)\n",
    "\n",
    "\n",
    "    def backward(self,X, W0, W1, h1, h0, alfa_rate):\n",
    "        # firstly lets compute error h1-y\n",
    "        error = self.my_error(h1)\n",
    "        bla_W1 = W1\n",
    "        # first lets update W1 which is far easier W1 = (h0)T *(h1 - Y)\n",
    "        transpose_h0 = np.transpose(h0)\n",
    "        error = error * self.derivative_zigmoid(h1)\n",
    "\n",
    "        # now lets update W0 too which is bit complex.\n",
    "        # W0 = XT.(ERROR).W1T\n",
    "        transpose_X = np.transpose(X)\n",
    "        transpose_W1 = np.transpose(bla_W1)\n",
    "\n",
    "\n",
    "        first_step = np.dot(error, transpose_W1)\n",
    "        second_step = np.dot(transpose_X, first_step)\n",
    "        delta_x = np.dot(error, np.transpose(np.dot(self.W0, self.W1)))\n",
    "        W0-=second_step*alfa_rate\n",
    "        W1 -= np.dot (transpose_h0, error)*alfa_rate\n",
    "#         print(W0)\n",
    "#         print(W1)\n",
    "        return delta_x\n",
    "    \n",
    "\n",
    "    def predict(self):\n",
    "        \n",
    "        h0, h1 = self.feed_forward(self.X, self.W0, self.W1)\n",
    "        delta_x = self.backward(self.X, self.W0, self.W1, h1, h0, 0.00001)\n",
    "#         print(self.cross_entropy(h1,Y))\n",
    "        return delta_x, h1\n",
    "#         return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# im = Image.open('../Letters/'+'ე'+'/'+'ე10.jpg')\n",
    "# im2arr = np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## LETS INITIALIZE OUR LAYERS AND FILTERS\n",
    "# X = im2arr\n",
    "# Y = [[0,1,0,0,0,0,0,0,0,0]]\n",
    "# Y=np.array(Y)\n",
    "learning_rate = 0.000007\n",
    "# here we will initialize first layer filters\n",
    "# first_layer_filter = Filter(np.random.randn(5,5))\n",
    "first_layer_filters = []\n",
    "first_layer_filters.append(1)\n",
    "\n",
    "# here we will initialize second layer filters\n",
    "# second_layer_filter = Filter(np.random.randn(3,3))\n",
    "second_layer_filters = []\n",
    "second_layer_filters.append(1)\n",
    "\n",
    "# here we will initialize second layer filters\n",
    "filter_array = []\n",
    "filter_array.append(2)\n",
    "filter_array.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### lets initialize CNN class\n",
    "# cnn = CNN(X,filter_array)\n",
    "# dense_class = Dense(None,Y)\n",
    "cnn = CNN(None,filter_array)\n",
    "dense_class = Dense(None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cnn,dense_class):\n",
    "    ### this method goes cnn part till flattened array.#         self.filters -= learning_rate*updated_filters\n",
    "\n",
    "    flatten_array = np.array(cnn.forward_prop())\n",
    "#     print(flatten_array.max())\n",
    "    flatten_array = np.reshape(np.array(flatten_array), (flatten_array.shape[0],1))\n",
    "    ###now lets start with dense class to work with neural network.\n",
    "    flatten_array = np.transpose(flatten_array)\n",
    "#     dense_class = Dense(np.transpose(flatten_array),Y)\n",
    "    dense_class.set_matrix(flatten_array)\n",
    "    delta_x, h1 = dense_class.predict()\n",
    "# #     print(delta_x.max())\n",
    "#     #listi maq matricebis\n",
    "    delta_x = cnn.unflatten(delta_x)\n",
    "#     #backward!!!!!!!\n",
    "#     # now we have to write flatten back to matrixes.\n",
    "#     ####\n",
    "    cnn.backward(delta_x)\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('../Letters/'+'ე'+'/'+'ე10.jpg')\n",
    "im2arr = np.array(im)\n",
    "X = im2arr\n",
    "Y = [[0,1,0,0,0,0,0,0,0,0]]\n",
    "Y=np.array(Y)\n",
    "def go_forest(X,Y):\n",
    "    cnn.set_x(X)\n",
    "    dense_class.set_y(Y)\n",
    "    for _ in range(15):\n",
    "        h1 = predict(cnn,dense_class)\n",
    "    print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "go_forest(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
