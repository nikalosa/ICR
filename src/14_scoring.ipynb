{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "9BSpd0mr8Oji",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_7t3_V28VX2",
    "colab_type": "text"
   },
   "source": [
    "# **Filter Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-0WtGLXL8WI5",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Filter:\n",
    "    \n",
    "    ### constructor takes array which will be filter\n",
    "    def __init__(self, filterM):\n",
    "        self.filter = np.array(filterM)\n",
    "        self.n = self.filter.shape[0]\n",
    "        self.m = self.filter.shape[1]\n",
    "        \n",
    "    ### returns filter\n",
    "    def get_filter(self):\n",
    "        return self.filter\n",
    "    \n",
    "    ### change filter by delta matrix\n",
    "    def add_delta(self, delta):\n",
    "        self.filter += delta\n",
    "\n",
    "    ### set the value of i,j element of the filter \n",
    "    def set(self, i, j, val):\n",
    "        self.filter[i][j] = val\n",
    "\n",
    "    ### returns the value of i,j element\n",
    "    def get(self, i, j):\n",
    "        return self.filter[i][j]\n",
    "\n",
    "    ### takes matrix and returns filtered matrix\n",
    "    def go_filter(self, data):\n",
    "        resultdata = np.zeros((data.shape[0] - self.n + 1, data.shape[1] - self.m + 1))\n",
    "        for i in range(data.shape[0] - self.n + 1):\n",
    "            for j in range(data.shape[1] - self.m + 1):\n",
    "                resultdata[i][j] = np.sum(self.filter * data[i:i+self.n,j:j+self.m])\n",
    "        return resultdata\n",
    "    \n",
    "    ### takes matrix and poolfilter dimension, returns max-pooled matrix\n",
    "    def go_maxpool(self, data, n, m):\n",
    "        resultdata = np.zeros((int(data.shape[0] / n) , int(data.shape[1] / m)))\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0, data.shape[1], m):\n",
    "                resultdata[int(i/n)][int(j/m)] = np.max(data[i:i+n, j:j+m])\n",
    "        return resultdata\n",
    "    \n",
    "    def go_maxpool(self,data,n,m):\n",
    "        resultdata = np.zeros(data.shape[0] / n , data.shape[1] / m)\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0,data.shape[1], m):\n",
    "                resultdata[i/n][j/m] = data[i:i+n, j:j+m].mean()\n",
    "        resultdata\n",
    "        \n",
    "        \n",
    "    def avarage_pooling_backforward(self,data, loss_data, n, m):\n",
    "        updated_data = np.zeros(data.shape)\n",
    "        for i in range(0, data.shape[0], n):\n",
    "            for j in range(0,data.shape[1], m):\n",
    "                data[i: i + n, j: j + m] = (m*n)*resultdata[i/n][j/m]\n",
    "\n",
    "    # pshiu, this method is pretty complex but in few words it updates convolutional filter\n",
    "    # looking at loss matrix and pre-matrixes.\n",
    "    def update_filter_one_matrix(self, data, loss_data):\n",
    "        learning_rate = 0.0003\n",
    "        updated_filter = np.zeros(self.filter.shape)\n",
    "        updated_data = np.zeros(data.shape)\n",
    "        for i in range(data.shape[0] + 1 - self.n):\n",
    "            for j in range(data.shape[1] + 1 - self.m):\n",
    "                # in summary resultdata[i][j] = self.filter * data[i:i+self.n, j : j+self.m]\n",
    "                my_filter_part_data = data[i:i+self.n, j : j+self.m]\n",
    "                my_data_part_data = updated_data[i:i+self.n, j : j+self.m]\n",
    "                for x in range(my_filter_part_data.shape[0]):\n",
    "                    for y in range(my_filter_part_data.shape[1]):\n",
    "                        updated_filter[x][y] += loss_data[i][j]*my_filter_part_data[x][y]\n",
    "                        # x derivative\n",
    "                        my_data_part_data[x][y] +=loss_data[i][j]*self.filter[x][y]\n",
    "                updated_data[i:i+self.n, j : j+self.m] = my_data_part_data\n",
    "        self.filter =self.filter -  learning_rate*updated_filter\n",
    "        return updated_filter, updated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EDXWcLGD8i4u",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzFAsOEX8qTO",
    "colab_type": "text"
   },
   "source": [
    "# **Layer Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3eXVZR928tar",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "class Layer:\n",
    "    ### constructor takes the list of filters \n",
    "    def __init__(self, num_filters):\n",
    "        self.filters = []\n",
    "        self.num_filters = num_filters\n",
    "        self.matrixes = []\n",
    "        self.preMatrixes = []\n",
    "        self.n = 2\n",
    "        self.m = 3\n",
    "    \n",
    "    ### returns the i-th filter\n",
    "    def get_filter(self, i):\n",
    "        return self.filters[i]\n",
    "    \n",
    "    ### return the list of filters\n",
    "    def get_filters(self):\n",
    "        return self.filters\n",
    "    \n",
    "    ### generates list of matrixes, from previous layer's matrixes and it's filters\n",
    "    def gen_matrixes(self, preMatrixes):\n",
    "        if len(self.filters) == 0:\n",
    "            for x in range(len(preMatrixes)):\n",
    "                each_filters = [Filter(np.random.randn(2,3)) for _ in range(self.num_filters)]\n",
    "                self.filters.append(each_filters)\n",
    "                \n",
    "        self.preMatrixes = preMatrixes\n",
    "        my_matrixes = [np.zeros((self.preMatrixes[0].shape[0] - self.n + 1, self.preMatrixes[0].shape[1] - self.m + 1)) for _ in range(self.num_filters)]\n",
    "\n",
    "        for x in range(len(preMatrixes)):\n",
    "            mat = preMatrixes[x]\n",
    "            temp = 0\n",
    "            for filt in self.filters[x]:\n",
    "                my_matrixes[temp] += filt.go_filter(mat)\n",
    "                temp+=1\n",
    "        self.matrixes = my_matrixes\n",
    "            \n",
    "        \n",
    "    ### returns i-th matrix of our matrixs' list\n",
    "    def get_matrix(self, i):\n",
    "        return self.matrix[i]\n",
    "    \n",
    "    ### returns list of matrixes\n",
    "    def get_matrixes(self):\n",
    "        return self.matrixes\n",
    "    \n",
    "    def layer_back_forward(self, loss_data_list):\n",
    "\n",
    "\n",
    "        pre_matrix_list = self.preMatrixes\n",
    "        updated_pre_matrix = [np.zeros(matr.shape) for matr in pre_matrix_list]\n",
    "        \n",
    "        updated_filters = []\n",
    "\n",
    "        for x in range(len(self.filters)):\n",
    "            each_filters = [np.zeros(matr.get_filter().shape) for matr in self.filters[x]]\n",
    "            updated_filters.append(each_filters)\n",
    "#         print(self.filters)\n",
    "        for x in range(len(self.filters)):\n",
    "            filt = self.filters[x]\n",
    "            for index in range(len(filt)):\n",
    "                cur_filt = filt[index]\n",
    "                cur_loss_data = loss_data_list[index]\n",
    "                for y in range(len(pre_matrix_list)):\n",
    "                    mat = pre_matrix_list[y]\n",
    "                    updated_filter, updated_data = cur_filt.update_filter_one_matrix(mat, cur_loss_data)\n",
    "                    updated_filters[x][index]+=updated_filter\n",
    "                    updated_pre_matrix[y]+=updated_data\n",
    "        return updated_pre_matrix\n",
    "           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fAFQ8Gwv8u_M",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j6kg0CH8xyx",
    "colab_type": "text"
   },
   "source": [
    "# CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "C1UeqgXq80oD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    ### constructor takes the starting matrix and filters list for each layer\n",
    "    ### layerFilters is 4D list\n",
    "    ### a = CNN(ar, )\n",
    "    ## update.\n",
    "    ## layerFilters listshi mewera listi filtrebisa layerebis mixedvit\n",
    "    ## exla shignit ubralod ricxvs chavwer tu ramdeni filtri unda mas.\n",
    "    def __init__(self, stMatrix, layerFilters):\n",
    "        self.stMatrix = stMatrix\n",
    "        self.layers = []\n",
    "        for layerFilter in layerFilters:\n",
    "#             print(layerFilter)\n",
    "            self.layers.append(Layer(layerFilter))\n",
    "    \n",
    "    ### returns all layer objects \n",
    "    def get_layers(self):\n",
    "        return self.layers\n",
    "    def set_x(self,X):\n",
    "        self.stMatrix = X\n",
    "    \n",
    "    ### returns i-th layer\n",
    "    def get_layer(self, i):\n",
    "        return self.layers[i]\n",
    "        \n",
    "    ### returns flattened np-array for fully connection NL\n",
    "    def forward_prop(self):\n",
    "        matrixList = [self.stMatrix]\n",
    "        for layer in self.layers:\n",
    "            layer.gen_matrixes(matrixList)\n",
    "            matrixList = layer.get_matrixes()\n",
    "        return self.flatten(matrixList)\n",
    "            \n",
    "    ### static method, flattens 3D array\n",
    "    def flatten(self, matrixList):\n",
    "\n",
    "        lst = []\n",
    "        for matrix in matrixList:\n",
    "            lst+=(matrix.flatten().tolist())\n",
    "        return lst\n",
    "    \n",
    "    def unflatten(self, flatten_matrix):\n",
    "        my_matrix = self.layers[len(self.layers)-1].get_matrixes()\n",
    "        my_loss_matrix = [np.zeros(tmp.shape) for tmp in my_matrix]\n",
    "        temp = 0\n",
    "        for index in range(len(my_loss_matrix)):\n",
    "            mat = my_loss_matrix[index]\n",
    "            for x in range(mat.shape[0]):\n",
    "                for y in range(mat.shape[1]):\n",
    "                    my_loss_matrix[index][x][y] = flatten_matrix[0][temp]\n",
    "                    temp += 1\n",
    "        return my_loss_matrix\n",
    "        \n",
    "    def backward(self, delta_x):\n",
    "        new_delta_x = delta_x\n",
    "        for layer in reversed(self.layers):\n",
    "            #WINEBIS listi da loss_datas listi\n",
    "            new_delta_x = layer.layer_back_forward(new_delta_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7_9mVvIG8_fc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpqB10rT9B1D",
    "colab_type": "text"
   },
   "source": [
    "# Dense Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uyKbbuFU9ELl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    \n",
    "    ### constructor takes parameter's array(flattened array) and answer array(1x10)\n",
    "    def __init__(self, X, Y):\n",
    "        self.i=0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.cachedLoss = []\n",
    "    \n",
    "    # just return e^(-z)\n",
    "    def my_exp(self,z):\n",
    "        return np.exp(-z)\n",
    "    \n",
    "    def set_y(self, Y):\n",
    "        self.Y=Y\n",
    "    \n",
    "    def set_matrix(self,mat):\n",
    "        if self.X is None:\n",
    "            self.W0 = np.random.randn(mat.size, 64)/100\n",
    "            self.W1 = np.random.randn(64, 10)/100\n",
    "        self.X = mat\n",
    "        \n",
    "        \n",
    "        # our zigmoid function\n",
    "    def zigmoid_function(self,z):\n",
    "        return 1/(1 + self.my_exp(z))\n",
    "    \n",
    "    def costfn_class(self, X, y):\n",
    "#         X = self.zigmoid_function(X)\n",
    "        error= -1*y*np.log(X) + (y-1)*np.log(1-X)\n",
    "#         my_sum = np.sum(abs(error))\n",
    "        return error\n",
    "    \n",
    "    def cross_entropy(self, predictions, targets, epsilon=1e-10):\n",
    "        predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "        ce = targets*np.log(predictions+1e-9) + (targets - 1)*np.log(1-predictions + 1e-9)\n",
    "        return ce\n",
    "    \n",
    "    \n",
    "        # ferivative of our zigmoid function\n",
    "    def derivative_zigmoid(self,z):\n",
    "        return self.my_exp(z) / np.power((1 + self.my_exp(z)), 2)\n",
    "    \n",
    "    # our fucntion doing feed forward alghoritm.\n",
    "    def feed_forward(self,X, W0, W1):\n",
    "        h0 = np.dot(X, W0)  # our first matrix after using first hidden layer W0\n",
    "    #     h0 = zigmoid_function(h0)  # our first matrix using zigmoid.\n",
    "        \n",
    "        h3 = np.dot(h0, W1) # our result after using second hidden layer W1\n",
    "        h1 = self.zigmoid_function(h3) # our result matrix after using zigmoid.\n",
    "        return h0, h1 # return result.\n",
    "    \n",
    "    # compute our error which is h1-y but we also take into consideration the zigmoid function.\n",
    "    def my_error(self,h1):\n",
    "#         error = h1 - self.Y\n",
    "#         return error\n",
    "        return self.cross_entropy(h1,self.Y)\n",
    "\n",
    "\n",
    "    def backward(self,X, W0, W1, h1, h0, alfa_rate):\n",
    "        # firstly lets compute error h1-y\n",
    "        error = self.my_error(h1)\n",
    "#         if self.cachedLoss != []:\n",
    "#             error = error*0.1 + 0.9*self.cachedLoss\n",
    "#         self.cachedLoss = error    \n",
    "        \n",
    "        bla_W1 = W1\n",
    "        # first lets update W1 which is far easier W1 = (h0)T *(h1 - Y)\n",
    "        transpose_h0 = np.transpose(h0)\n",
    "        error = error * self.derivative_zigmoid(h1)\n",
    "\n",
    "        # now lets update W0 too which is bit complex.\n",
    "        # W0 = XT.(ERROR).W1T\n",
    "        transpose_X = np.transpose(X)\n",
    "        transpose_W1 = np.transpose(bla_W1)\n",
    "\n",
    "\n",
    "        first_step = np.dot(error, transpose_W1)\n",
    "        second_step = np.dot(transpose_X, first_step)\n",
    "        delta_x = np.dot(error, np.transpose(np.dot(self.W0, self.W1)))\n",
    "        W0 -= second_step*alfa_rate\n",
    "        W1 -= np.dot (transpose_h0, error)*alfa_rate\n",
    "        return delta_x\n",
    "    \n",
    "\n",
    "    def predict(self, back):\n",
    "        h0, h1 = self.feed_forward(self.X, self.W0, self.W1)\n",
    "        delta_x = None\n",
    "        if back:\n",
    "            delta_x = self.backward(self.X, self.W0, self.W1, h1, h0, 0.0005)\n",
    "        return delta_x, h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "KIWhLLAM9FwP",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOTydl6Q9z3o",
    "colab_type": "text"
   },
   "source": [
    "# Main Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "dBD37eBw9i_w",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class Final:\n",
    "    def __init__(self, cnnOBJ, denseOBJ):\n",
    "        self.cnn = cnnOBJ\n",
    "        self.dense = denseOBJ\n",
    "        self.letters = ['ე', 'ი', 'კ', 'ჟ', 'რ', 'ტ', 'ფ', 'ქ', 'ყ', 'ჰ']\n",
    "        \n",
    "    def find_max_ind(arr):\n",
    "      index = 0\n",
    "      max_num = arr[0][0]\n",
    "      for i in range(len(arr[0])):\n",
    "          if arr[0][i] > max_num:\n",
    "              max_num = arr[0][i]\n",
    "              index = i\n",
    "      return index\n",
    "        \n",
    "    def go(self, img):\n",
    "        h = go_forest(img, [[1,0,0,0,0,0,0,0,0,0]], True, False)\n",
    "        ind = find_max_ind(h)\n",
    "        return self.letters[ind]\n",
    "    \n",
    "    def go_forest(X, Y, debug=False, back = True):\n",
    "        self.cnn.set_x(X)\n",
    "        self.dense.set_y(Y)\n",
    "        for _ in range(1):\n",
    "            h1 = predict(self.cnn, self.dense, back)\n",
    "        return h1\n",
    "    \n",
    "    def predict(cnn, dense_class, back):\n",
    "        flatten_array = np.array(cnn.forward_prop())\n",
    "        flatten_array = np.reshape(np.array(flatten_array), (flatten_array.shape[0],1))\n",
    "\n",
    "        #now lets start with dense class to work with neural network.\n",
    "        flatten_array = np.transpose(flatten_array)\n",
    "\n",
    "        # dense_class = Dense(np.transpose(flatten_array),Y)\n",
    "        dense_class.set_matrix(flatten_array)\n",
    "        delta_x, h1 = dense_class.predict(back)\n",
    "\n",
    "        if back:\n",
    "            #listi maq matricebis\n",
    "            delta_x = cnn.unflatten(delta_x)\n",
    "            cnn.backward(delta_x)\n",
    "\n",
    "        return h1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lABaDoV09d2r",
    "colab_type": "text"
   },
   "source": [
    "# Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nWlEWxHw95VC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.misc import imsave\n",
    "\n",
    "input_folder = './input/ე' #needs to be filled\n",
    "\n",
    "def cutImg(path, rotate, size):\n",
    "    im = Image.open(path)\n",
    "    rgb_im = im.convert('RGB')\n",
    "    arr = np.array(rgb_im)\n",
    "\n",
    "    startTop = 0\n",
    "    endBot = arr.shape[1]\n",
    "    letterFound = False\n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        isLetter = False\n",
    "        for j in range(arr.shape[1]):\n",
    "            if arr[i][j][0] <= 210 and arr[i][j][1] <= 210 and arr[i][j][2] <= 210:\n",
    "                isLetter = True\n",
    "                break\n",
    "\n",
    "        if isLetter and not letterFound:\n",
    "            letterFound = True\n",
    "            startTop = i\n",
    "\n",
    "        if not isLetter and letterFound:\n",
    "            letterFound = False\n",
    "            endBot = i\n",
    "\n",
    "        letterFound = isLetter\n",
    "\n",
    "    cropped = rgb_im.crop((0, startTop, arr.shape[1], endBot))\n",
    "\n",
    "    if rotate == 1:\n",
    "        arr1 = np.array(cropped)\n",
    "        arr1 = np.rot90(arr1, axes=(0, -2))\n",
    "        cropped = Image.fromarray(arr1)\n",
    "    elif rotate == -1:\n",
    "        arr1 = np.array(cropped)\n",
    "        arr1 = np.rot90(arr1, axes=(-2, 0))\n",
    "        cropped = Image.fromarray(arr1)\n",
    "\n",
    "    if size != 0:\n",
    "        cropped = cropped.resize((size, size), resample=Image.BILINEAR)\n",
    "\n",
    "    cropped.save(path)\n",
    "\n",
    "\n",
    "def cropImg(path):\n",
    "    cutImg(path, 1, 0)\n",
    "    cutImg(path, -1, 64)\n",
    "\n",
    "def add_border(input_image, border, color=0):\n",
    "    img = Image.open(input_image)\n",
    "    if isinstance(border, int) or isinstance(border, tuple):\n",
    "        bimg = ImageOps.expand(img, border=border, fill=color)\n",
    "    else:\n",
    "        raise RuntimeError('Border is not an integer or tuple!')\n",
    "    return bimg\n",
    "    \n",
    "def binarize_array(numpy_array, threshold=180):\n",
    "    for i in range(len(numpy_array)):\n",
    "        for j in range(len(numpy_array[0])):\n",
    "            if numpy_array[i][j] > threshold:\n",
    "                numpy_array[i][j] = 255\n",
    "            else:\n",
    "                numpy_array[i][j] = 0\n",
    "    return numpy_array\n",
    "\n",
    "def convert_bw(img):\n",
    "    image = img.convert('L')  # convert image to monochrome\n",
    "    image_arr = np.array(image)\n",
    "    image_arr = binarize_array(image_arr)\n",
    "    return image_arr\n",
    "\n",
    "def format_picture(image_path):\n",
    "    img_borders = add_border(image_path, border=10, color='white')\n",
    "\n",
    "    img_convert = img_borders.convert(\"RGBA\")\n",
    "    fff = Image.new('RGBA', img_convert.size, (255,)*4)\n",
    "    out = Image.composite(img_convert, fff, img_convert)\n",
    "    out = out.convert(img_borders.mode)\n",
    "    \n",
    "    img_bw = convert_bw(out)\n",
    "    img_name = \"{}.{}\".format('test', 'jpg')\n",
    "    save_path = \"{}/{}\".format(input_folder, img_name)\n",
    "\n",
    "    imsave(save_path, img_bw)\n",
    "    img = Image.open(save_path)\n",
    "    img = img.resize((40, 40), resample=Image.BILINEAR)\n",
    "    img.save(save_path)\n",
    "\n",
    "    imsave(\"{}\".format(save_path), img)\n",
    "    cropImg(\"{}\".format(save_path))\n",
    "    image = Image.open(save_path)\n",
    "    image = image.resize((40,40), resample = Image.BILINEAR)\n",
    "\n",
    "    return convert_bw(image)\n",
    "\n",
    "def generate_ans(image):\n",
    "    arr = np.asarray(image)\n",
    "    return arr\n",
    "\n",
    "\n",
    "import pickle  \n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    filehandler = open(\"savedModel1.pkl\", 'rb') \n",
    "    model1 = pickle.load(filehandler)\n",
    "  \n",
    "    image_files = os.listdir(input_folder)\n",
    "    result = []\n",
    "    for index in range(len(image_files)):\n",
    "        image_array = format_picture('{}/{}'.format(input_folder, image_files[index]))\n",
    "        image_array = image_array/255\n",
    "        print(image_array.shape)\n",
    "        ans = model1.go(image_array)\n",
    "        result += [[str(index), ans]]\n",
    "\n",
    "\n",
    "    filename = 'result.csv'\n",
    "    with open(filename, 'w') as f:\n",
    "        csv.writer(f).writerows(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "14_scoring.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
